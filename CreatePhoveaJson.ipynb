{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Phovea Import Configuration\n",
    "\n",
    "*Author: Alexander Lex; alex@sci.utah.edu *\n",
    "\n",
    "This script creates an index.json file containing configurations to load/parse all the CSV files stored in the path specified below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing files as DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the path to the files\n",
    "path = \"\";\n",
    "# the file names, as an array of strings\n",
    "files = []\n",
    "# Can't distinguish some ID columns from ints. Specify the column headers that should be treated as IDs.\n",
    "idtypes = [];    \n",
    "# the delimiter used in the file\n",
    "delimiter = \",\"\n",
    "# If you want to specify a range of a numerical value manually. \n",
    "# This is a dictionary of \"column header\" (string) to a two-field array (from - to)\n",
    "man_range = {}\n",
    "# If you want to specify a range manually for all labels that contain the wildcard string. \n",
    "# Wildcard as key, two-from array as value\n",
    "wildcard_man_range = {}\n",
    "\n",
    "case = \"suicide\"\n",
    "#case = \"artists\"\n",
    "#case = \"AIDS\"\n",
    "\n",
    "if(case == \"artists\"):\n",
    "    path = \"data/artists/\"\n",
    "    files = [\"number_one_artists.csv\"];\n",
    "    delimiter = \"\\t\"\n",
    "elif(case == \"suicide\"):\n",
    "    path = \"data/suicide/\"\n",
    "    files = [\"AllFamiliesAttributes.csv\",\"AllFamiliesDescend.csv\",\"TenFamiliesAttr.csv\",\n",
    "         \"TenFamiliesAttrAnon.csv\",\"TenFamiliesDescend.csv\",\"TenFamiliesDescendAnon.csv\", \n",
    "             \"AllAutismFamiliesDescend.csv\", \"AllAutismFamiliesAttributes.csv\"]\n",
    "    idtypes = {\"ID\", \"STATENUM\", \"KindredID\", \"RelativeID\", \"LabID\", \"MaID\", \"PaID\", \"OMEDID\", \"ArchivePersonID\"}\n",
    "    man_range[\"FirstBMI\"] = [15,45]\n",
    "    man_range[\"MaxBMI\"] = [15,45]\n",
    "    wildcard_man_range[\"Nr.Diag_\"] = [0,10]\n",
    "elif (case == \"companies\"):\n",
    "    path = \"data/companies/\"\n",
    "    files = [\"Company Data  - Company Core Infor.csv\", \"Company Data  - Links.csv\"]\n",
    "elif (case == \"AIDS\"):\n",
    "    path = \"data/AIDS/\"\n",
    "    files = [\"AIDS_Countries.csv\", \"AIDS_Years.csv\"];\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_map = {}\n",
    "for file in files:\n",
    "    file_map[file] = pd.read_csv(join(path, file), delimiter=delimiter)\n",
    "    print(file)\n",
    "    #print(file_map[file].columns.values)\n",
    "    print(file_map[file].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual settings\n",
    "\n",
    "There are some things that the script can't guess: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If a column has more than this many labels, we consider it text, not a category\n",
    "categorical_label_threshold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createColumnConfiguration(df):\n",
    "    columns = []\n",
    "    for column_name in df.columns.values[1:]:\n",
    "        #print(column_name)\n",
    "        column = df[column_name]\n",
    "        col_desc = {}\n",
    "        columns.append(col_desc)\n",
    "        col_desc[\"name\"] = column_name\n",
    "        value = {}\n",
    "        col_desc[\"value\"] = value\n",
    "        # IDTypes have to be listed manually\n",
    "        if(column_name in idtypes):\n",
    "            value[\"type\"] = \"idtype\";\n",
    "        # Because of missing values, pandas treats all numericals as floats\n",
    "        elif(column.dtype == \"float64\" or column.dtype == \"int64\"):\n",
    "            col_sum = column.sum()\n",
    "            # Check whether it's actually an integer\n",
    "            if(math.isclose(round(col_sum), col_sum, rel_tol=0.0001)):            \n",
    "                value[\"type\"] = \"int\"\n",
    "            else:\n",
    "                value[\"type\"] = \"real\"\n",
    "            range = []\n",
    "            # Check for manually defined ranges\n",
    "            if(column_name in man_range):\n",
    "                range = man_range[column_name]\n",
    "            else:  \n",
    "                range.append(0)\n",
    "                range.append(float(column.max()))\n",
    "                \n",
    "                for man_range_value in wildcard_man_range:\n",
    "                    if(man_range_value in column_name):\n",
    "                        print(\"Tada\", column_name)\n",
    "                        range = wildcard_man_range[man_range_value]\n",
    "                        break;\n",
    "                #column.min()\n",
    "                # range stats at 0 goes to max\n",
    "               \n",
    "            value[\"range\"] = range\n",
    "        # If more than threshold unique values, we treat it as string\n",
    "        elif((len(column.unique()) > categorical_label_threshold)):\n",
    "            value[\"type\"] = \"string\"\n",
    "        else:\n",
    "            value[\"type\"] = \"categorical\"\n",
    "            categories = []\n",
    "            value[\"categories\"] = categories;\n",
    "            for category in column.unique():\n",
    "                isNaN = False;\n",
    "                try:\n",
    "                    isNaN = np.isnan(category)\n",
    "                    #print(\"Nan here\", isNan, category)\n",
    "                except TypeError:\n",
    "                    pass\n",
    "                \n",
    "                if(isNaN):\n",
    "                    continue\n",
    "                \n",
    "                category_desc = {}\n",
    "                \n",
    "                if(type(category) == bool):\n",
    "                    if(category):\n",
    "                        category_desc[\"name\"] = \"True\"\n",
    "                    else:\n",
    "                        category_desc[\"name\"] = \"False\"\n",
    "                else:\n",
    "                    category_desc[\"name\"] = str(category)\n",
    "                category_desc[\"color\"] = \"red\"\n",
    "                categories.append(category_desc)\n",
    "    return columns;    \n",
    "        \n",
    "    #print(json.dumps(columns, separators=(',', ':')))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import_template = \"\"\"\n",
    "{\"name\": \"\",\n",
    "  \"type\": \"table\",\n",
    "  \"id\": \"\",\n",
    "  \"separator\": \",\",\n",
    "  \"quotechar\": \"\",\n",
    "  \"description\": \"autogenerated\",\n",
    "  \"creator\": \"autogenerated\",\n",
    "  \"path\": \"\",\n",
    "  \"idcolumn\": 0,\n",
    "  \"idtype\": \"\",\n",
    "  \"size\": [],\n",
    "  \"columns\": []\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createJsonForFile(filename):\n",
    "    df = file_map[filename]\n",
    "    columns = createColumnConfiguration(df)\n",
    "    json_config = json.loads(import_template)\n",
    "    json_config[\"separator\"] = delimiter\n",
    "    json_config[\"quotechar\"] = '\"'\n",
    "    json_config[\"columns\"] = columns\n",
    "    name = filename.split('.')[0]\n",
    "    json_config[\"id\"] = name\n",
    "    json_config[\"path\"] = filename\n",
    "    json_config[\"name\"] = name\n",
    "    json_config[\"idtype\"] = df.columns.values[0]\n",
    "    size = [df.shape[0],df.shape[1]-1]\n",
    "    json_config[\"size\"] = size\n",
    "    return json_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "configs = []\n",
    "for k, v in file_map.items():\n",
    "    json_config = createJsonForFile(k);\n",
    "    # print(json_config)\n",
    "    configs.append(json_config)\n",
    "    \n",
    "\n",
    "json_dump = json.dumps(configs, separators=(',', ':'), sort_keys=True, indent=2)\n",
    "f = open(path+\"index.json\", 'w')\n",
    "f.write(json_dump)\n",
    "print(json_dump)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
